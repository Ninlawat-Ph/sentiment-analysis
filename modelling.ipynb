{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninlawat-Ph/sentiment-analysis/blob/master/modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUKV95VpfAik",
        "colab_type": "code",
        "outputId": "7e4d7766-f463-4d60-855a-9884b96fa572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "!pip install googletrans\n",
        "!pip install tqdm --upgrade\n",
        "!pip install twython"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2020.4.5.1)\n",
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.45.0)\n",
            "Requirement already satisfied: twython in /usr/local/lib/python3.6/dist-packages (3.8.2)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdvIdNDPfv1g",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cRcucvLfxfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "from random import randint\n",
        "\n",
        "# Translation\n",
        "from googletrans import Translator\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import mark_negation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrjJPFI6fay9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore data\n",
        "data1= pd.read_csv(\"data_lanna_en.csv\")\n",
        "data2= pd.read_csv(\"data_siriraj_piyamaharajkarun_en.csv\")\n",
        "data3= pd.read_csv(\"data_vajira_hospital_en.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-4t-BiibQw_",
        "colab_type": "text"
      },
      "source": [
        "## Sentence-level Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIocmEK6cNdl",
        "colab_type": "code",
        "outputId": "783e5298-6d6f-4a71-bff1-53ce92347252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJd5a6WbT48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_level_polarity(df, target):\n",
        "  sentences = []\n",
        "  scores = []\n",
        "  for i in df.index:\n",
        "    en = df.loc[i, target]\n",
        "    score = df.loc[i, \"score\"]\n",
        "    s = sent_tokenize(en)\n",
        "    sentences = sentences + s\n",
        "    scores = scores + [score]*len(s)\n",
        "  return pd.DataFrame({\"sentences\": sentences, \"scores\": scores})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bh7qSckbXDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sentiment(sentence):\n",
        "  sa = SentimentIntensityAnalyzer()\n",
        "  sentiment_distribution = sa.polarity_scores(sentence)\n",
        "  score = sentiment_distribution.get(\"compound\")\n",
        "  \n",
        "  if score >= 0.05:\n",
        "    return \"positive\"\n",
        "  elif score <= -0.05:\n",
        "    return \"negative\"\n",
        "  else:\n",
        "    return \"neutral\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0va3xxUATOq",
        "colab_type": "code",
        "outputId": "ca10311e-bba1-4c6f-e9a2-7cb0ea8e867f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o-cUwuvNVx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1_temp = sent_level_polarity(df=data1, target=\"en\")\n",
        "data1_temp[\"sentiment_polarity\"] = data1_temp[\"sentences\"].apply(lambda x: predict_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFF6Zeu_cRqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2_temp = sent_level_polarity(df=data2, target=\"en\")\n",
        "data2_temp[\"sentiment_polarity\"] = data2_temp[\"sentences\"].apply(lambda x: predict_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCStHHTjeuCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data3_temp = sent_level_polarity(df=data3, target=\"en\")\n",
        "data3_temp[\"sentiment_polarity\"] = data3_temp[\"sentences\"].apply(lambda x: predict_sentiment(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPj9dXyUfFmy",
        "colab_type": "text"
      },
      "source": [
        "## Exclude Neutral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8WVG6EofHfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1_temp = data1_temp[data1_temp[\"sentiment_polarity\"] != \"neutral\"].reset_index(drop=True)\n",
        "data2_temp = data2_temp[data2_temp[\"sentiment_polarity\"] != \"neutral\"].reset_index(drop=True)\n",
        "data3_temp = data3_temp[data3_temp[\"sentiment_polarity\"] != \"neutral\"].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyOF4FiafUON",
        "colab_type": "text"
      },
      "source": [
        "## Label encoding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKD1Z5M8fX4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label encoding the data \n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSpLOUHfj9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4LgTFDjflUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encode it is 1 for positive and 0 for negative.\n",
        "data1_temp['label']=le.fit_transform(data1_temp['sentiment_polarity'])\n",
        "data2_temp['label']=le.fit_transform(data2_temp['sentiment_polarity'])\n",
        "data3_temp['label']=le.fit_transform(data3_temp['sentiment_polarity'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL7WsOiZfvZW",
        "colab_type": "text"
      },
      "source": [
        "## Concat dataframe each hospital "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM_ftTqXe3zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = [data1_temp, data2_temp, data3_temp]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACg372aNf9Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQ7esHUf_mq",
        "colab_type": "code",
        "outputId": "c1fc4d13-5d18-41b8-c13e-fba0494b0a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>scores</th>\n",
              "      <th>sentiment_polarity</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You take very good care of check points too.</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It feels very good to work with nursing regula...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A look tidy If relatives Or have a friend at w...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent patient care The singers all the time</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doctors and nurses cared very good.</td>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...  label\n",
              "0       You take very good care of check points too.  ...      1\n",
              "1  It feels very good to work with nursing regula...  ...      1\n",
              "2  A look tidy If relatives Or have a friend at w...  ...      1\n",
              "3    Excellent patient care The singers all the time  ...      1\n",
              "4                Doctors and nurses cared very good.  ...      1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXQa9p35PcJO",
        "colab_type": "code",
        "outputId": "0b2b157f-6191-442c-d81e-4f3a346301ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(963, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KdKeUmbgN4b",
        "colab_type": "text"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMlDSgKmgSmB",
        "colab_type": "code",
        "outputId": "fbc7d143-db4c-4ca9-bb05-9fae16c321ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vicpfceIytZJ",
        "colab_type": "text"
      },
      "source": [
        "###  Stopword removal "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WM12isKHjR",
        "colab_type": "code",
        "outputId": "5826b8a3-cdd9-41ed-f56d-a1d2e54a9fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sw = stopwords.words(\"english\")\n",
        "sw[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMR4fUgcKPsF",
        "colab_type": "text"
      },
      "source": [
        "## Create the new column of tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4cuyQ1twaRs",
        "colab_type": "text"
      },
      "source": [
        "### tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idANprGOL-6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import sent_tokenize, word_tokenize\n",
        "data[\"tokens\"] = data[\"sentences\"].apply(lambda x: \n",
        "                                        sum([word_tokenize(sentence) \n",
        "                                        for sentence in \n",
        "                                        sent_tokenize(x.lower())], []))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dGT5TUGOcV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"tokens\"] = data[\"tokens\"].apply(lambda x: list(set(x) - set(sw)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG1DEqBQGc5",
        "colab_type": "code",
        "outputId": "6a98e2b3-8991-4843-ceac-8c9b8f3a98ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>scores</th>\n",
              "      <th>sentiment_polarity</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You take very good care of check points too.</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[points, ., care, good, check, take]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It feels very good to work with nursing regula...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[nursing, regulation, ., work, good, feels]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A look tidy If relatives Or have a friend at w...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[tidy, friend, ., work, look, would, hospital,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent patient care The singers all the time</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[singers, patient, care, excellent, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doctors and nurses cared very good.</td>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[doctors, ., nurses, good, cared]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...                                             tokens\n",
              "0       You take very good care of check points too.  ...               [points, ., care, good, check, take]\n",
              "1  It feels very good to work with nursing regula...  ...        [nursing, regulation, ., work, good, feels]\n",
              "2  A look tidy If relatives Or have a friend at w...  ...  [tidy, friend, ., work, look, would, hospital,...\n",
              "3    Excellent patient care The singers all the time  ...          [singers, patient, care, excellent, time]\n",
              "4                Doctors and nurses cared very good.  ...                  [doctors, ., nurses, good, cared]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njS7cqEiQO1Z",
        "colab_type": "text"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOJVTs_vQTca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URcVI9ury_E5",
        "colab_type": "text"
      },
      "source": [
        "###  TFIDF vectorization and LDA vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6QVbA8YQmKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"prep_sentence\"] = data[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "corpus = data[\"prep_sentence\"].tolist()\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPiFxJS4Q2dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=30)\n",
        "X = lda.fit_transform(X_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK5AgKz4gY5p",
        "colab_type": "code",
        "outputId": "2f4d34a5-7592-4b5b-f008-06776141deea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>scores</th>\n",
              "      <th>sentiment_polarity</th>\n",
              "      <th>label</th>\n",
              "      <th>tokens</th>\n",
              "      <th>prep_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You take very good care of check points too.</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[points, ., care, good, check, take]</td>\n",
              "      <td>points . care good check take</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It feels very good to work with nursing regula...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[nursing, regulation, ., work, good, feels]</td>\n",
              "      <td>nursing regulation . work good feels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A look tidy If relatives Or have a friend at w...</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[tidy, friend, ., work, look, would, hospital,...</td>\n",
              "      <td>tidy friend . work look would hospital recomme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent patient care The singers all the time</td>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[singers, patient, care, excellent, time]</td>\n",
              "      <td>singers patient care excellent time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doctors and nurses cared very good.</td>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "      <td>[doctors, ., nurses, good, cared]</td>\n",
              "      <td>doctors . nurses good cared</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...                                      prep_sentence\n",
              "0       You take very good care of check points too.  ...                      points . care good check take\n",
              "1  It feels very good to work with nursing regula...  ...               nursing regulation . work good feels\n",
              "2  A look tidy If relatives Or have a friend at w...  ...  tidy friend . work look would hospital recomme...\n",
              "3    Excellent patient care The singers all the time  ...                singers patient care excellent time\n",
              "4                Doctors and nurses cared very good.  ...                        doctors . nurses good cared\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncoi4NnDggjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv(\"hospital_prediction.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgY7NNK81BPn",
        "colab_type": "text"
      },
      "source": [
        "# Modeling "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ8RDAjM1nOT",
        "colab_type": "text"
      },
      "source": [
        "### Import model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99l9vB5TIHmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgJ1DuUIIfBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnzBJ6j161YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZYQDPYZ-QKr",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR2axt-jwtB1",
        "colab_type": "code",
        "outputId": "cb9762a2-96eb-4f3b-f932-630507c23770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#Random Forest classifier\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
        "cv = cross_validate(classifier, X_train, y_train, cv=10)\n",
        "print(cv['test_score'])\n",
        "print(cv['test_score'].mean())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.76623377 0.75324675 0.75324675 0.74025974 0.75324675 0.77922078\n",
            " 0.79220779 0.74025974 0.79220779 0.71428571]\n",
            "0.7584415584415585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdKKgTtg2qDA",
        "colab_type": "text"
      },
      "source": [
        "Random forests เป็นวิธีที่แม่นยำและมีประสิทธิภาพ ไม่ได้รับผลกระทบจากปัญหา overfitting  ไม่มี bias สามารถจัดการกับปัญหา missing value ได้"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W55nXn_a-64t",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imCfLFWfxE37",
        "colab_type": "code",
        "outputId": "b040f01c-aa3a-40b5-b740-14b095b96ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "xgb=xgb.XGBClassifier()\n",
        "cv = cross_validate(xgb, X_train, y_train, cv=10)\n",
        "print(cv['test_score'])\n",
        "print(cv['test_score'].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.77922078 0.80519481 0.75324675 0.76623377 0.76623377 0.81818182\n",
            " 0.77922078 0.79220779 0.77922078 0.76623377]\n",
            "0.7805194805194805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVD4Vjyh4vMb",
        "colab_type": "text"
      },
      "source": [
        "XGBoost ย่อมาจาก Extreme Gradient Boosting ฐานมาจาก Gradient Boosting Machines  ใช้เทคนิค regularization เพื่อลดการ overfitting มีความเร็วในการประมวลผลที่สูง วิธีการคือ เอา Decision Tree มา train ต่อๆกันหลายๆ tree โดยที่แต่ละ decision tree จะเรียนรู้จาก error ของ tree ก่อนหน้า ทำให้ความแม่นยำของในการทำ prediction จะ แม่นยำขึ้น"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouycGv7u-_CX",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtefqUbmJlSB",
        "colab_type": "code",
        "outputId": "a60d0649-abd3-4f12-f361-d1d73230974b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#Accuracy using Naive Bayes Model\n",
        "NB = MultinomialNB()\n",
        "cv = cross_validate(NB, X_train, y_train, cv=10)\n",
        "print(cv['test_score'])\n",
        "print(cv['test_score'].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.80519481 0.80519481 0.80519481 0.79220779 0.79220779 0.79220779\n",
            " 0.79220779 0.79220779 0.79220779 0.79220779]\n",
            "0.7961038961038961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8TXxIC28uRK",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes หลักการของวิธีการนี้จะใช้การคำนวณความน่าจะเป็นเหมาะกับ dataset จำนวณมากและมี feature ที่ไม่ขึ้นต่อกันมีการจัดจำแนกประเภทอย่างง่ายประยุกต์ใช้กับจัดจำแนกประเภทข้อความ(text classification) model ไม่ซับซ้อน  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiUTvYj5_JEp",
        "colab_type": "text"
      },
      "source": [
        "# Pick XGboost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeiK0gXuBtuU",
        "colab_type": "code",
        "outputId": "261572ed-0fac-4ae7-cbb3-6a793e0ecc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "xgb=xgb.XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "preds2=xgb.predict(X_test)\n",
        "print(classification_report(preds2,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.40      0.08         5\n",
            "           1       0.98      0.76      0.85       188\n",
            "\n",
            "    accuracy                           0.75       193\n",
            "   macro avg       0.51      0.58      0.46       193\n",
            "weighted avg       0.96      0.75      0.83       193\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjSMTJ3MB-7Y",
        "colab_type": "code",
        "outputId": "1c31fec5-15f3-4a36-83d9-949c09fafff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,preds2), sep = '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "[[  2  46]\n",
            " [  3 142]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}