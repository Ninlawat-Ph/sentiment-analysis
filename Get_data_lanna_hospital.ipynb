{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get data lanna hospital.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhiUCcACS+rzA51M4ketld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninlawat-Ph/sentiment-analysis/blob/master/Get_data_lanna_hospital.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H8HQ4K0VkHl",
        "colab_type": "code",
        "outputId": "4d93e783-a544-451b-f30e-aa6b54bf80d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "!pip install googletrans\n",
        "!pip install tqdm --upgrade\n",
        "!pip install twython"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.45.0)\n",
            "Requirement already satisfied: twython in /usr/local/lib/python3.6/dist-packages (3.8.2)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZe9oSysWFZb",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSjXmzpzWHhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "from random import randint\n",
        "\n",
        "# Translation\n",
        "from googletrans import Translator\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import mark_negation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BTEXDpoWKjt",
        "colab_type": "code",
        "outputId": "7fbb9fd5-4671-4e4f-e70e-99f4354cbfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# Download resources\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"vader_lexicon\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BAZiBHQWOXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def honestdoc_comment(url):\n",
        "    \"\"\"\n",
        "    This function is to scrap data from a webboard (https://www.honestdocs.com).\n",
        "\n",
        "    INPUT\n",
        "    url : String\n",
        "      URL of the target website\n",
        "    \n",
        "    OUTPUT\n",
        "    comment : List\n",
        "      List of comments\n",
        "    score : List\n",
        "      List of rating score\n",
        "    \"\"\"\n",
        "    #create connection\n",
        "    data = requests.get(url)\n",
        "    print(\"requests code : {}\".format(data.status_code)) \n",
        "    print(\"note\\n2xx: success\\n4xx, 5xx: error\")\n",
        "    \n",
        "    #scrape comment and score\n",
        "    start_time = time() #start scraping data from page1\n",
        "    r = requests.get(url, params=dict(query=\"web scraping\",page=1)) \n",
        "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
        "    n = len(soup.find_all(\"div\",{\"class\":\"comments__content\"})) #find n of items in the page\n",
        "    \n",
        "    #extract each item\n",
        "    comment = [soup.find_all(\"div\",\n",
        "                             {\"class\":\"comments__content\"})[i].get_text().strip() for i in range(0,n)]\n",
        "    score = [soup.find_all(\"span\",\n",
        "                           {\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"] for i in range(0,n)]\n",
        "    elapsed_time = time() - start_time #finish scraping data from page1\n",
        "    print(\"Time used for scraping data from page - 1 : {} s\".format(elapsed_time))\n",
        "    sleep(randint(1,3)) #mimic human behavior\n",
        "           \n",
        "    p = 2 #start scraping data from page2\n",
        "    while n > 0: #until the number of items in a page = 0\n",
        "        start_time = time() \n",
        "        r = requests.get(url, params=dict(query=\"web scraping\",page=p))\n",
        "        soup = BeautifulSoup(r.text,\"html.parser\")\n",
        "        n = len(soup.find_all(\"div\",{\"class\":\"comments__content\"}))\n",
        "        [comment.append(soup.find_all(\"div\",\n",
        "                                      {\"class\":\"comments__content\"})[i].get_text().strip()) for i in range(0,n)]\n",
        "        [score.append(soup.find_all(\"span\",\n",
        "                                    {\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"]) for i in range(0,n)]\n",
        "        elapsed_time = time() - start_time\n",
        "        print(\"Time used for scraping data from page - {} : {} s\".format(p, elapsed_time))\n",
        "        p +=1\n",
        "        sleep(randint(1,3))\n",
        "    \n",
        "    #backup data \n",
        "    pd.DataFrame({\"comment\": comment, \n",
        "                  \"score\": score}).to_csv(\"comment_\"+str(url[url.rfind(\"/\")+1:]) + \".csv\", index=False)\n",
        "    \n",
        "    return comment, score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL4v-YERWRti",
        "colab_type": "text"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV0MwfT9WTQa",
        "colab_type": "code",
        "outputId": "46b9d243-a530-4159-e1fb-3157a90c8f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "nts, scores = honestdoc_comment(r\"https://www.honestdocs.co/hospitals/lanna-hospital\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requests code : 200\n",
            "note\n",
            "2xx: success\n",
            "4xx, 5xx: error\n",
            "Time used for scraping data from page - 1 : 1.2567455768585205 s\n",
            "Time used for scraping data from page - 2 : 1.235698938369751 s\n",
            "Time used for scraping data from page - 3 : 1.230867862701416 s\n",
            "Time used for scraping data from page - 4 : 1.2272541522979736 s\n",
            "Time used for scraping data from page - 5 : 1.2355847358703613 s\n",
            "Time used for scraping data from page - 6 : 1.235170602798462 s\n",
            "Time used for scraping data from page - 7 : 1.2453463077545166 s\n",
            "Time used for scraping data from page - 8 : 1.3068902492523193 s\n",
            "Time used for scraping data from page - 9 : 1.2156188488006592 s\n",
            "Time used for scraping data from page - 10 : 1.243983507156372 s\n",
            "Time used for scraping data from page - 11 : 1.2221341133117676 s\n",
            "Time used for scraping data from page - 12 : 1.2345731258392334 s\n",
            "Time used for scraping data from page - 13 : 1.236027479171753 s\n",
            "Time used for scraping data from page - 14 : 1.2204232215881348 s\n",
            "Time used for scraping data from page - 15 : 1.224440574645996 s\n",
            "Time used for scraping data from page - 16 : 0.9801840782165527 s\n",
            "Time used for scraping data from page - 17 : 0.9713530540466309 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R0XmESvW9zq",
        "colab_type": "text"
      },
      "source": [
        "## Comment Translation The comments in this study are either Thai or English. Therefore, they should be standardized as English. Google translate API is the tool in this study AND Remove emoji in string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubx1z9bzW_X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore data\n",
        "data_comment_lanna_hospital = pd.read_csv(\"comment_lanna-hospital.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSaN01PE1h9w",
        "colab_type": "text"
      },
      "source": [
        "### Remove emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RulaR_bBp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform emoji to sting\n",
        "import re\n",
        "import sys\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNBooD_mbCmO",
        "colab_type": "code",
        "outputId": "db2de2a5-31cb-443d-be3b-92f059e6a789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tqdm.pandas()\n",
        "data_comment_lanna_hospital[\"non_emojis\"] = data_comment_lanna_hospital.progress_apply(lambda x: remove_emoji(x[\"comment\"]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:00<00:00, 3928.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMY9FxkvzxQ7",
        "colab_type": "text"
      },
      "source": [
        "### Translate en to thai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQzXy3tFbofN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def th2en(comment):\n",
        "  return Translator().translate(comment, src=\"th\", dest=\"en\").text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fozCKj1btDD",
        "colab_type": "code",
        "outputId": "c27cc835-24e5-47d5-a0e6-471485bb3022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data_comment_lanna_hospital[\"en\"] = data_comment_lanna_hospital.progress_apply(lambda x: th2en(x[\"non_emojis\"]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:05<00:00,  7.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IveCU-TMcLsj",
        "colab_type": "code",
        "outputId": "c917a3dd-a6a7-4d82-e0be-d2cafa2dc6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "data_comment_lanna_hospital.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>score</th>\n",
              "      <th>non_emojis</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>คุณหมอดูแลดีมากเลยค่ะ ตรวจละเอียด รักษาได้ตรงจ...</td>\n",
              "      <td>5</td>\n",
              "      <td>คุณหมอดูแลดีมากเลยค่ะ ตรวจละเอียด รักษาได้ตรงจ...</td>\n",
              "      <td>You take very good care of check points too. M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>คุณหมอและพยาบาลใส่ใจดูแลดีมากคะ​ ประทับใจทุกคร...</td>\n",
              "      <td>4</td>\n",
              "      <td>คุณหมอและพยาบาลใส่ใจดูแลดีมากคะ​ ประทับใจทุกคร...</td>\n",
              "      <td>Doctors and nurses cared very good. Impressed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>โดนแมวที่เลี้ยงไว้กัดคะ ได้ไปทำแผลที่ รพ.นี้ เ...</td>\n",
              "      <td>4</td>\n",
              "      <td>โดนแมวที่เลี้ยงไว้กัดคะ ได้ไปทำแผลที่ รพ.นี้ เ...</td>\n",
              "      <td>A cat that bites you. Do not wound the hospita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>มีอาการกรดไหลย้อน ทำให้หายใจไม่ออก และเหนื่อยม...</td>\n",
              "      <td>5</td>\n",
              "      <td>มีอาการกรดไหลย้อน ทำให้หายใจไม่ออก และเหนื่อยม...</td>\n",
              "      <td>Symptoms of GERD Asphyxiate And tired I can no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>มีประกันสังคมที่ โรงพยาบาลลานนาเชียงใหม่ค่ะประ...</td>\n",
              "      <td>5</td>\n",
              "      <td>มีประกันสังคมที่ โรงพยาบาลลานนาเชียงใหม่ค่ะประ...</td>\n",
              "      <td>With Social Security Hospital Lanna me very im...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  ...                                                 en\n",
              "0  คุณหมอดูแลดีมากเลยค่ะ ตรวจละเอียด รักษาได้ตรงจ...  ...  You take very good care of check points too. M...\n",
              "1  คุณหมอและพยาบาลใส่ใจดูแลดีมากคะ​ ประทับใจทุกคร...  ...  Doctors and nurses cared very good. Impressed ...\n",
              "2  โดนแมวที่เลี้ยงไว้กัดคะ ได้ไปทำแผลที่ รพ.นี้ เ...  ...  A cat that bites you. Do not wound the hospita...\n",
              "3  มีอาการกรดไหลย้อน ทำให้หายใจไม่ออก และเหนื่อยม...  ...  Symptoms of GERD Asphyxiate And tired I can no...\n",
              "4  มีประกันสังคมที่ โรงพยาบาลลานนาเชียงใหม่ค่ะประ...  ...  With Social Security Hospital Lanna me very im...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmrWQJA-0B01",
        "colab_type": "text"
      },
      "source": [
        "### Restore data to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Ww6El0coLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_comment_lanna_hospital.to_csv(\"data_lanna_en.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}