{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get data vajira hospital .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfFnmypTyiTSyjaLOEd7cy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ninlawat-Ph/sentiment-analysis/blob/master/Get_data_vajira_hospital_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI9YfQeAWhiS",
        "colab_type": "code",
        "outputId": "49a6c03a-eeec-45f6-f884-93ed1bc484c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "!pip install googletrans\n",
        "!pip install tqdm --upgrade\n",
        "!pip install twython"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.45.0)\n",
            "Requirement already satisfied: twython in /usr/local/lib/python3.6/dist-packages (3.8.2)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUZTH8YrXOyY",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo7XyQwkXUtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "from random import randint\n",
        "\n",
        "# Translation\n",
        "from googletrans import Translator\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLP\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import mark_negation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0wvFNj_XYji",
        "colab_type": "code",
        "outputId": "32806272-7f51-4446-fcda-026cbf893d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "# Download resources\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"vader_lexicon\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaG1EKLWXeyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def honestdoc_comment(url):\n",
        "    \"\"\"\n",
        "    This function is to scrap data from a webboard (https://www.honestdocs.com).\n",
        "\n",
        "    INPUT\n",
        "    url : String\n",
        "      URL of the target website\n",
        "    \n",
        "    OUTPUT\n",
        "    comment : List\n",
        "      List of comments\n",
        "    score : List\n",
        "      List of rating score\n",
        "    \"\"\"\n",
        "    #create connection\n",
        "    data = requests.get(url)\n",
        "    print(\"requests code : {}\".format(data.status_code)) \n",
        "    print(\"note\\n2xx: success\\n4xx, 5xx: error\")\n",
        "    \n",
        "    #scrape comment and score\n",
        "    start_time = time() #start scraping data from page1\n",
        "    r = requests.get(url, params=dict(query=\"web scraping\",page=1)) \n",
        "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
        "    n = len(soup.find_all(\"div\",{\"class\":\"comments__content\"})) #find n of items in the page\n",
        "    \n",
        "    #extract each item\n",
        "    comment = [soup.find_all(\"div\",\n",
        "                             {\"class\":\"comments__content\"})[i].get_text().strip() for i in range(0,n)]\n",
        "    score = [soup.find_all(\"span\",\n",
        "                           {\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"] for i in range(0,n)]\n",
        "    elapsed_time = time() - start_time #finish scraping data from page1\n",
        "    print(\"Time used for scraping data from page - 1 : {} s\".format(elapsed_time))\n",
        "    sleep(randint(1,3)) #mimic human behavior\n",
        "           \n",
        "    p = 2 #start scraping data from page2\n",
        "    while n > 0: #until the number of items in a page = 0\n",
        "        start_time = time() \n",
        "        r = requests.get(url, params=dict(query=\"web scraping\",page=p))\n",
        "        soup = BeautifulSoup(r.text,\"html.parser\")\n",
        "        n = len(soup.find_all(\"div\",{\"class\":\"comments__content\"}))\n",
        "        [comment.append(soup.find_all(\"div\",\n",
        "                                      {\"class\":\"comments__content\"})[i].get_text().strip()) for i in range(0,n)]\n",
        "        [score.append(soup.find_all(\"span\",\n",
        "                                    {\"class\":\"stars star-rating\"})[i].attrs[\"data-score\"]) for i in range(0,n)]\n",
        "        elapsed_time = time() - start_time\n",
        "        print(\"Time used for scraping data from page - {} : {} s\".format(p, elapsed_time))\n",
        "        p +=1\n",
        "        sleep(randint(1,3))\n",
        "    \n",
        "    #backup data \n",
        "    pd.DataFrame({\"comment\": comment, \n",
        "                  \"score\": score}).to_csv(\"comment_\"+str(url[url.rfind(\"/\")+1:]) + \".csv\", index=False)\n",
        "    \n",
        "    return comment, score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7m8YFrnaK14",
        "colab_type": "code",
        "outputId": "0c277487-6617-4217-cbd7-b50ace086c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "nts, scores = honestdoc_comment(r\"https://www.honestdocs.co/hospitals/vajira-hospital\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "requests code : 200\n",
            "note\n",
            "2xx: success\n",
            "4xx, 5xx: error\n",
            "Time used for scraping data from page - 1 : 0.3784043788909912 s\n",
            "Time used for scraping data from page - 2 : 0.3783433437347412 s\n",
            "Time used for scraping data from page - 3 : 0.3951752185821533 s\n",
            "Time used for scraping data from page - 4 : 0.4026823043823242 s\n",
            "Time used for scraping data from page - 5 : 0.3813750743865967 s\n",
            "Time used for scraping data from page - 6 : 0.3945739269256592 s\n",
            "Time used for scraping data from page - 7 : 0.3875112533569336 s\n",
            "Time used for scraping data from page - 8 : 0.4575080871582031 s\n",
            "Time used for scraping data from page - 9 : 0.381026029586792 s\n",
            "Time used for scraping data from page - 10 : 0.46209144592285156 s\n",
            "Time used for scraping data from page - 11 : 0.3865983486175537 s\n",
            "Time used for scraping data from page - 12 : 0.3861565589904785 s\n",
            "Time used for scraping data from page - 13 : 0.3887917995452881 s\n",
            "Time used for scraping data from page - 14 : 0.5306754112243652 s\n",
            "Time used for scraping data from page - 15 : 0.38480591773986816 s\n",
            "Time used for scraping data from page - 16 : 0.3814277648925781 s\n",
            "Time used for scraping data from page - 17 : 0.38356828689575195 s\n",
            "Time used for scraping data from page - 18 : 0.38640594482421875 s\n",
            "Time used for scraping data from page - 19 : 0.38956570625305176 s\n",
            "Time used for scraping data from page - 20 : 0.2894020080566406 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjRNbowtdNNX",
        "colab_type": "text"
      },
      "source": [
        "## Comment Translation The comments in this study are either Thai or English. Therefore, they should be standardized as English. Google translate API is the tool in this study AND Remove emoji in string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TR4okwCbUkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore data\n",
        "data_comment_vajira_hospital= pd.read_csv(\"comment_vajira-hospital.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bhZO8oT1Obn",
        "colab_type": "text"
      },
      "source": [
        "### Remove emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvhH_853bVdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform emoji to sting\n",
        "import re\n",
        "import sys\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhvNMmsrbXsw",
        "colab_type": "code",
        "outputId": "dcdc27bc-65bc-43cb-fb83-13fba3b8f4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tqdm.pandas()\n",
        "data_comment_vajira_hospital[\"non_emojis\"] = data_comment_vajira_hospital.progress_apply(lambda x: remove_emoji(x[\"comment\"]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 57/57 [00:00<00:00, 2846.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fJNMLfp1SA6",
        "colab_type": "text"
      },
      "source": [
        "### Translate en to thai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAoKgNfcb1FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def th2en(comment):\n",
        "  return Translator().translate(comment, src=\"th\", dest=\"en\").text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF_LmINGb580",
        "colab_type": "code",
        "outputId": "48c04610-781c-470c-9bda-b13509e7ad9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data_comment_vajira_hospital[\"en\"] = data_comment_vajira_hospital.progress_apply(lambda x: th2en(x[\"non_emojis\"]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 57/57 [01:07<00:00,  1.18s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdfLRjfQcZ1K",
        "colab_type": "code",
        "outputId": "6924cd82-c693-4dc5-a4a9-9bf0547501dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "data_comment_vajira_hospital.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>score</th>\n",
              "      <th>non_emojis</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>โรงพยาบาลวชิรพยาบาลไปครั้งแรก ต้องทำการทะเบียน...</td>\n",
              "      <td>5</td>\n",
              "      <td>โรงพยาบาลวชิรพยาบาลไปครั้งแรก ต้องทำการทะเบียน...</td>\n",
              "      <td>Wachira Hospital nurses go first. Must registe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ดูแลดีมากค่ะถึงแม้คนจะเยอะจัดการได้ดี คุณหมอก็...</td>\n",
              "      <td>5</td>\n",
              "      <td>ดูแลดีมากค่ะถึงแม้คนจะเยอะจัดการได้ดี คุณหมอก็...</td>\n",
              "      <td>Care very good, although it is not handled wel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>บริการดีมากครับทั้งการบริการที่สะดวกรวดเร็วจึง...</td>\n",
              "      <td>5</td>\n",
              "      <td>บริการดีมากครับทั้งการบริการที่สะดวกรวดเร็วจึง...</td>\n",
              "      <td>Service is very good and the service friendly,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>เจ้าหน้าที่ พยาบาล แพทย์ ส่วนใหญ่บริการดี ให้ค...</td>\n",
              "      <td>4</td>\n",
              "      <td>เจ้าหน้าที่ พยาบาล แพทย์ ส่วนใหญ่บริการดี ให้ค...</td>\n",
              "      <td>Most physicians, nursing staff, good service. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>เข้าทำการตรวจภายใน ตรวจหามะเร็งปากมดลูก สถานที...</td>\n",
              "      <td>5</td>\n",
              "      <td>เข้าทำการตรวจภายใน ตรวจหามะเร็งปากมดลูก สถานที...</td>\n",
              "      <td>To make a Detection of Cervical Cancer Very cl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  ...                                                 en\n",
              "0  โรงพยาบาลวชิรพยาบาลไปครั้งแรก ต้องทำการทะเบียน...  ...  Wachira Hospital nurses go first. Must registe...\n",
              "1  ดูแลดีมากค่ะถึงแม้คนจะเยอะจัดการได้ดี คุณหมอก็...  ...  Care very good, although it is not handled wel...\n",
              "2  บริการดีมากครับทั้งการบริการที่สะดวกรวดเร็วจึง...  ...  Service is very good and the service friendly,...\n",
              "3  เจ้าหน้าที่ พยาบาล แพทย์ ส่วนใหญ่บริการดี ให้ค...  ...  Most physicians, nursing staff, good service. ...\n",
              "4  เข้าทำการตรวจภายใน ตรวจหามะเร็งปากมดลูก สถานที...  ...  To make a Detection of Cervical Cancer Very cl...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0js9jn61WYf",
        "colab_type": "text"
      },
      "source": [
        "### Restore data to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umesGcbSd2AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_comment_vajira_hospital.to_csv(\"data_vajira_hospital_en.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}